bash-4.1# spark-submit --class "project1.Job1" --master yarn-client --driver-memory 1g --executor-memory 768m --executor-cores 4 /home/workspace/Project1-spark/target/spark1-0.0.1-SNAPSHOT.jar input/1999_2006.csv output/log_test_spark
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
17/05/06 11:22:24 WARN util.Utils: Your hostname, localhost resolves to a loopback address: 127.0.0.1; using 172.19.0.2 instead (on interface eth0)
17/05/06 11:22:24 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/05/06 11:22:24 INFO spark.SecurityManager: Changing view acls to: root
17/05/06 11:22:24 INFO spark.SecurityManager: Changing modify acls to: root
17/05/06 11:22:24 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/05/06 11:22:24 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/05/06 11:22:24 INFO Remoting: Starting remoting
17/05/06 11:22:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38887]
17/05/06 11:22:24 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@localhost:38887]
17/05/06 11:22:24 INFO util.Utils: Successfully started service 'sparkDriver' on port 38887.
17/05/06 11:22:24 INFO spark.SparkEnv: Registering MapOutputTracker
17/05/06 11:22:24 INFO spark.SparkEnv: Registering BlockManagerMaster
17/05/06 11:22:24 INFO storage.DiskBlockManager: Created local directory at /tmp/spark-local-20170506112224-edf3
17/05/06 11:22:24 INFO util.Utils: Successfully started service 'Connection manager for block manager' on port 41023.
17/05/06 11:22:24 INFO network.ConnectionManager: Bound socket to port 41023 with id = ConnectionManagerId(localhost,41023)
17/05/06 11:22:24 INFO storage.MemoryStore: MemoryStore started with capacity 530.0 MB
17/05/06 11:22:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/05/06 11:22:24 INFO storage.BlockManagerMasterActor: Registering block manager localhost:41023 with 530.0 MB RAM, BlockManagerId(<driver>, localhost, 41023, 0)
17/05/06 11:22:24 INFO storage.BlockManagerMaster: Registered BlockManager
17/05/06 11:22:24 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b094fbdc-dafa-4a08-9d3e-c2d046554601
17/05/06 11:22:24 INFO spark.HttpServer: Starting HTTP Server
17/05/06 11:22:24 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/05/06 11:22:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42751
17/05/06 11:22:24 INFO util.Utils: Successfully started service 'HTTP file server' on port 42751.
17/05/06 11:22:25 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/05/06 11:22:25 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/05/06 11:22:25 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/05/06 11:22:25 INFO ui.SparkUI: Started SparkUI at http://localhost:4040
17/05/06 11:22:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/06 11:22:25 INFO spark.SparkContext: Added JAR file:/home/workspace/Project1-spark/target/spark1-0.0.1-SNAPSHOT.jar at http://172.19.0.2:42751/jars/spark1-0.0.1-SNAPSHOT.jar with timestamp 1494084145444
--args is deprecated. Use --arg instead.
17/05/06 11:22:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
17/05/06 11:22:25 INFO yarn.Client: Got cluster metric info from ResourceManager, number of NodeManagers: 1
17/05/06 11:22:25 INFO yarn.Client: Max mem capabililty of a single resource in this cluster 8192
17/05/06 11:22:25 INFO yarn.Client: Preparing Local resources
17/05/06 11:22:26 WARN yarn.ClientBase: SPARK_JAR detected in the system environment. This variable has been deprecated in favor of the spark.yarn.jar configuration variable.
17/05/06 11:22:26 INFO yarn.Client: Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "localhost" port: 9000 file: "/spark/spark-assembly-1.1.1-hadoop2.4.0.jar" } size: 139018438 timestamp: 1417554561860 type: FILE visibility: PUBLIC)
17/05/06 11:22:26 INFO yarn.Client: Setting up the launch environment
17/05/06 11:22:26 WARN yarn.ClientBase: SPARK_JAR detected in the system environment. This variable has been deprecated in favor of the spark.yarn.jar configuration variable.
17/05/06 11:22:26 INFO yarn.Client: Setting up container launch context
17/05/06 11:22:26 INFO yarn.Client: Yarn AM launch context:
17/05/06 11:22:26 INFO yarn.Client:   class:   org.apache.spark.deploy.yarn.ExecutorLauncher
17/05/06 11:22:26 INFO yarn.Client:   env:     Map(CLASSPATH -> $PWD:$PWD/__spark__.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/yarn/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*:$PWD/__app__.jar:$PWD/*, SPARK_YARN_CACHE_FILES_FILE_SIZES -> 139018438, SPARK_YARN_STAGING_DIR -> .sparkStaging/application_1494079809711_0024/, SPARK_YARN_CACHE_FILES_VISIBILITIES -> PUBLIC, SPARK_USER -> root, SPARK_YARN_MODE -> true, SPARK_YARN_CACHE_FILES_TIME_STAMPS -> 1417554561860, SPARK_YARN_CACHE_FILES -> hdfs://localhost:9000/spark/spark-assembly-1.1.1-hadoop2.4.0.jar#__spark__.jar)
17/05/06 11:22:26 INFO yarn.Client:   command: $JAVA_HOME/bin/java -server -Xmx1024m -Djava.io.tmpdir=$PWD/tmp '-Dspark.tachyonStore.folderName=spark-57e5bd22-4e43-4ce7-8d57-62aefd7afd2c' '-Dspark.driver.memory=1g' '-Dspark.executor.memory=768m' '-Dspark.executorEnv.JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk.x86_64' '-Dspark.yarn.secondary.jars=' '-Dspark.driver.host=localhost' '-Dspark.driver.appUIHistoryAddress=' '-Dspark.app.name=Job1' '-Dspark.driver.appUIAddress=localhost:4040' '-Dspark.jars=file:/home/workspace/Project1-spark/target/spark1-0.0.1-SNAPSHOT.jar' '-Dspark.fileserver.uri=http://172.19.0.2:42751' '-Dspark.master=yarn-client' '-Dspark.driver.port=38887' '-Dspark.executor.cores=4' org.apache.spark.deploy.yarn.ExecutorLauncher --class 'notused' --jar  null  --arg  'localhost:38887' --executor-memory 768 --executor-cores 4 --num-executors  2 1> <LOG_DIR>/stdout 2> <LOG_DIR>/stderr
17/05/06 11:22:26 INFO spark.SecurityManager: Changing view acls to: root
17/05/06 11:22:26 INFO spark.SecurityManager: Changing modify acls to: root
17/05/06 11:22:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/05/06 11:22:26 INFO yarn.Client: Submitting application to ResourceManager
17/05/06 11:22:26 INFO impl.YarnClientImpl: Submitted application application_1494079809711_0024
17/05/06 11:22:26 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
         appMasterRpcPort: -1
         appStartTime: 1494084146220
         yarnAppState: ACCEPTED

17/05/06 11:22:27 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
         appMasterRpcPort: -1
         appStartTime: 1494084146220
         yarnAppState: ACCEPTED

17/05/06 11:22:28 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
         appMasterRpcPort: -1
         appStartTime: 1494084146220
         yarnAppState: ACCEPTED

17/05/06 11:22:28 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> localhost, PROXY_URI_BASES -> http://localhost:8088/proxy/application_1494079809711_0024), /proxy/application_1494079809711_0024
17/05/06 11:22:28 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/05/06 11:22:29 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
         appMasterRpcPort: 0
         appStartTime: 1494084146220
         yarnAppState: RUNNING

17/05/06 11:22:31 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@localhost:40633/user/Executor#-758394931] with ID 1
17/05/06 11:22:31 INFO util.RackResolver: Resolved localhost to /default-rack
17/05/06 11:22:31 INFO storage.BlockManagerMasterActor: Registering block manager localhost:43549 with 397.4 MB RAM, BlockManagerId(1, localhost, 43549, 0)
17/05/06 11:22:32 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@localhost:37079/user/Executor#-2001174109] with ID 2
17/05/06 11:22:32 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/05/06 11:22:32 INFO storage.MemoryStore: ensureFreeSpace(74080) called with curMem=0, maxMem=555755765
17/05/06 11:22:32 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 72.3 KB, free 529.9 MB)
17/05/06 11:22:32 INFO storage.MemoryStore: ensureFreeSpace(17418) called with curMem=74080, maxMem=555755765
17/05/06 11:22:32 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 17.0 KB, free 529.9 MB)
17/05/06 11:22:32 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41023 (size: 17.0 KB, free: 530.0 MB)
17/05/06 11:22:32 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
17/05/06 11:22:32 INFO mapred.FileInputFormat: Total input paths to process : 1
17/05/06 11:22:32 INFO storage.BlockManagerMasterActor: Registering block manager localhost:42681 with 397.4 MB RAM, BlockManagerId(2, localhost, 42681, 0)
17/05/06 11:22:33 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/05/06 11:22:33 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/05/06 11:22:33 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/05/06 11:22:33 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/05/06 11:22:33 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/05/06 11:22:33 INFO spark.SparkContext: Starting job: saveAsTextFile at Job1.java:65
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Registering RDD 3 (mapToPair at Job1.java:36)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at Job1.java:49)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Registering RDD 9 (coalesce at Job1.java:65)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Got job 0 (saveAsTextFile at Job1.java:65) with 1 output partitions (allowLocal=false)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Final stage: Stage 0(saveAsTextFile at Job1.java:65)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 3)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Missing parents: List(Stage 3)
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[3] at mapToPair at Job1.java:36), which has no missing parents
17/05/06 11:22:33 INFO storage.MemoryStore: ensureFreeSpace(4896) called with curMem=91498, maxMem=555755765
17/05/06 11:22:33 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 529.9 MB)
17/05/06 11:22:33 INFO storage.MemoryStore: ensureFreeSpace(2756) called with curMem=96394, maxMem=555755765
17/05/06 11:22:33 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 529.9 MB)
17/05/06 11:22:33 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41023 (size: 2.7 KB, free: 530.0 MB)
17/05/06 11:22:33 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
17/05/06 11:22:33 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[3] at mapToPair at Job1.java:36)
17/05/06 11:22:33 INFO cluster.YarnClientClusterScheduler: Adding task set 1.0 with 1 tasks
17/05/06 11:22:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, PROCESS_LOCAL, 1305 bytes)
17/05/06 11:22:33 INFO network.ConnectionManager: Accepted connection from [localhost/127.0.0.1:44078]
17/05/06 11:22:33 INFO network.SendingConnection: Initiating connection to [localhost/127.0.0.1:43549]
17/05/06 11:22:33 INFO network.SendingConnection: Connected to [localhost/127.0.0.1:43549], 1 messages pending
17/05/06 11:22:33 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43549 (size: 2.7 KB, free: 397.4 MB)
17/05/06 11:22:33 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43549 (size: 17.0 KB, free: 397.4 MB)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Stage 1 (mapToPair at Job1.java:36) finished in 1.541 s
17/05/06 11:22:34 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1548 ms on localhost (1/1)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/05/06 11:22:34 INFO scheduler.DAGScheduler: running: Set()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: waiting: Set(Stage 0, Stage 2, Stage 3)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: failed: Set()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Missing parents for Stage 0: List(Stage 3)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Missing parents for Stage 2: List()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Missing parents for Stage 3: List(Stage 2)
17/05/06 11:22:34 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[5] at mapToPair at Job1.java:49), which is now runnable
17/05/06 11:22:34 INFO storage.MemoryStore: ensureFreeSpace(3464) called with curMem=99150, maxMem=555755765
17/05/06 11:22:34 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 529.9 MB)
17/05/06 11:22:34 INFO storage.MemoryStore: ensureFreeSpace(1949) called with curMem=102614, maxMem=555755765
17/05/06 11:22:34 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1949.0 B, free 529.9 MB)
17/05/06 11:22:34 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41023 (size: 1949.0 B, free: 530.0 MB)
17/05/06 11:22:34 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[5] at mapToPair at Job1.java:49)
17/05/06 11:22:34 INFO cluster.YarnClientClusterScheduler: Adding task set 2.0 with 1 tasks
17/05/06 11:22:34 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1, localhost, PROCESS_LOCAL, 1046 bytes)
17/05/06 11:22:34 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43549 (size: 1949.0 B, free: 397.4 MB)
17/05/06 11:22:34 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 2 to sparkExecutor@localhost:34823
17/05/06 11:22:34 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 127 bytes
17/05/06 11:22:34 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 216 ms on localhost (1/1)
17/05/06 11:22:34 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Stage 2 (mapToPair at Job1.java:49) finished in 0.215 s
17/05/06 11:22:34 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/05/06 11:22:34 INFO scheduler.DAGScheduler: running: Set()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: waiting: Set(Stage 0, Stage 3)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: failed: Set()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Missing parents for Stage 0: List(Stage 3)
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Missing parents for Stage 3: List()
17/05/06 11:22:34 INFO scheduler.DAGScheduler: Submitting Stage 3 (CoalescedRDD[9] at coalesce at Job1.java:65), which is now runnable
17/05/06 11:22:35 INFO storage.MemoryStore: ensureFreeSpace(4544) called with curMem=104563, maxMem=555755765
17/05/06 11:22:35 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.4 KB, free 529.9 MB)
17/05/06 11:22:35 INFO storage.MemoryStore: ensureFreeSpace(2562) called with curMem=109107, maxMem=555755765
17/05/06 11:22:35 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 529.9 MB)
17/05/06 11:22:35 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:41023 (size: 2.5 KB, free: 530.0 MB)
17/05/06 11:22:35 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (CoalescedRDD[9] at coalesce at Job1.java:65)
17/05/06 11:22:35 INFO cluster.YarnClientClusterScheduler: Adding task set 3.0 with 1 tasks
17/05/06 11:22:35 INFO util.RackResolver: Resolved  to /default-rack
17/05/06 11:22:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2, localhost, RACK_LOCAL, 1335 bytes)
17/05/06 11:22:35 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:43549 (size: 2.5 KB, free: 397.4 MB)
17/05/06 11:22:35 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@localhost:34823
17/05/06 11:22:35 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 127 bytes
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Stage 3 (coalesce at Job1.java:65) finished in 0.470 s
17/05/06 11:22:35 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/05/06 11:22:35 INFO scheduler.DAGScheduler: running: Set()
17/05/06 11:22:35 INFO scheduler.DAGScheduler: waiting: Set(Stage 0)
17/05/06 11:22:35 INFO scheduler.DAGScheduler: failed: Set()
17/05/06 11:22:35 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 469 ms on localhost (1/1)
17/05/06 11:22:35 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Missing parents for Stage 0: List()
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[11] at saveAsTextFile at Job1.java:65), which is now runnable
17/05/06 11:22:35 INFO storage.MemoryStore: ensureFreeSpace(58728) called with curMem=111669, maxMem=555755765
17/05/06 11:22:35 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 57.4 KB, free 529.8 MB)
17/05/06 11:22:35 INFO storage.MemoryStore: ensureFreeSpace(20350) called with curMem=170397, maxMem=555755765
17/05/06 11:22:35 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.9 KB, free 529.8 MB)
17/05/06 11:22:35 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:41023 (size: 19.9 KB, free: 530.0 MB)
17/05/06 11:22:35 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[11] at saveAsTextFile at Job1.java:65)
17/05/06 11:22:35 INFO cluster.YarnClientClusterScheduler: Adding task set 0.0 with 1 tasks
17/05/06 11:22:35 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 1057 bytes)
17/05/06 11:22:35 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:43549 (size: 19.9 KB, free: 397.4 MB)
17/05/06 11:22:35 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@localhost:34823
17/05/06 11:22:35 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 127 bytes
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Stage 0 (saveAsTextFile at Job1.java:65) finished in 0.261 s
17/05/06 11:22:35 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 3) in 260 ms on localhost (1/1)
17/05/06 11:22:35 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/05/06 11:22:35 INFO spark.SparkContext: Job finished: saveAsTextFile at Job1.java:65, took 2.6746747 s
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
17/05/06 11:22:35 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
17/05/06 11:22:35 INFO ui.SparkUI: Stopped Spark web UI at http://localhost:4040
17/05/06 11:22:35 INFO scheduler.DAGScheduler: Stopping DAGScheduler
17/05/06 11:22:35 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/05/06 11:22:35 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/05/06 11:22:35 INFO cluster.YarnClientSchedulerBackend: Stopped
17/05/06 11:22:36 INFO network.ConnectionManager: Removing SendingConnection to ConnectionManagerId(localhost,43549)
17/05/06 11:22:36 INFO network.ConnectionManager: Removing ReceivingConnection to ConnectionManagerId(localhost,43549)
17/05/06 11:22:36 ERROR network.ConnectionManager: Corresponding SendingConnection to ConnectionManagerId(localhost,43549) not found
17/05/06 11:22:37 INFO spark.MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
17/05/06 11:22:37 INFO network.ConnectionManager: Selector thread was interrupted!
17/05/06 11:22:37 INFO network.ConnectionManager: Removing SendingConnection to ConnectionManagerId(localhost,43549)
17/05/06 11:22:37 INFO network.ConnectionManager: Removing ReceivingConnection to ConnectionManagerId(localhost,43549)
17/05/06 11:22:37 ERROR network.ConnectionManager: Corresponding SendingConnection to ConnectionManagerId(localhost,43549) not found
17/05/06 11:22:37 WARN network.ConnectionManager: All connections not cleaned up
17/05/06 11:22:37 INFO network.ConnectionManager: ConnectionManager stopped
17/05/06 11:22:37 INFO storage.MemoryStore: MemoryStore cleared
17/05/06 11:22:37 INFO storage.BlockManager: BlockManager stopped
17/05/06 11:22:37 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/05/06 11:22:37 INFO spark.SparkContext: Successfully stopped SparkContext
17/05/06 11:22:37 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/05/06 11:22:37 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.